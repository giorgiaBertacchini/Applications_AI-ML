
model: "PPO"  # A2C, DQN, PPO

time_step_length: 0.65

time_step_count: 11000  # 20 years

episode_count: 20
episode_welch_count: 5

episode_length: 9125  # 25 years

learning_total_timesteps: 42000  # 75 years

gamma: 0.99  # tested: 0.99 (best results), 0.5, 0.1


normalize_state: True  # just a bit better results than False
normalize_reward: True  # just a bit better results than False

normalizing:
  min_wip: 0
  max_wip: 150
  min_processing_time: 0
  max_processing_time: 35
  min_slack: -35
  max_slack: 50
  min_reward: -750
  max_reward: 250


tensorflow_flag: False  # for find the maximums and minimums of the normalizations
