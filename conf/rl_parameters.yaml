
model: "DQN"  # A2C, DQN, PPO

time_step_length: 0.65

time_step_count: 6000  # 18250

episode_count: 2
episode_welch_count: 2

episode_length: 9125  # 25 years

learning_total_timesteps: 40000  # 36000

gamma: 0.99


normalize_state: True
normalize_reward: True

normalizing:
  min_wip: 0
  max_wip: 150
  min_processing_time: 0
  max_processing_time: 35
  min_slack: -35
  max_slack: 50
  min_reward: -750
  max_reward: 250


tensorflow_enabled: False
